{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0c360f7f21a72e5083ad62d0bcf8bfd45b1ab32f2b7b7db5d7b0dd8bb45545b1c",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 100\n",
    "num_samples = num_data // 2\n",
    "num_features = 2\n",
    "num_centers = 4\n",
    "rand_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rand_seed)\n",
    "data = np.random.rand(num_data, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = rbf_kernel(data, data, 1.8)\n",
    "# print(f\"K: {K.shape}\")\n",
    "# np.dot(K[k, :], K[:, k]) / (K[k, k] + lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# make some fake data X and y\n",
    "np.random.seed(0)\n",
    "train_X = np.random.rand(100, 3)\n",
    "train_y = np.random.randint(0,10, size=100)\n",
    "# print(train_y.min(), train_y.max())\n",
    "svc = SVC()\n",
    "svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "test_X = np.random.rand(1, 3)\n",
    "svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X, Y, sigma):\n",
    "    N, K = X.shape\n",
    "    M = Y.shape[0]\n",
    "\n",
    "    K_xy = np.ones(M)*np.sum(X**2) + np.ones(N)*np.sum(Y**2) - 2*np.dot(X, Y.transpose())\n",
    "    K_xy = np.exp(-0.5 * K_xy / sigma**2)\n",
    "\n",
    "    return K_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "K: (100, 100)\n[[1.71466761e-09 1.66656512e-09 1.65321677e-09 1.74954823e-09\n  1.70960115e-09 1.71470853e-09 1.80204387e-09 1.37665086e-09\n  1.60898489e-09 1.84456260e-09 1.87865801e-09 1.71403276e-09\n  1.56780576e-09 1.68403776e-09 1.59729894e-09 1.65549985e-09\n  1.63415999e-09 1.53404248e-09 1.69596142e-09 1.81984291e-09\n  1.56166663e-09 1.52173624e-09 1.73215239e-09 1.42259585e-09\n  1.52516465e-09 1.61896652e-09 1.61337948e-09 1.43243586e-09\n  1.57605878e-09 1.52398585e-09 1.40449758e-09 1.53735612e-09\n  1.49642404e-09 1.56656877e-09 1.57072572e-09 1.74584147e-09\n  1.79921586e-09 1.52540527e-09 1.43738290e-09 1.44016585e-09\n  1.54294650e-09 1.57162268e-09 1.55728608e-09 1.48848065e-09\n  1.80593167e-09 1.63178128e-09 1.59812878e-09 1.45913990e-09\n  1.48019590e-09 1.53700604e-09 1.58851952e-09 1.86882826e-09\n  1.58044015e-09 1.67362164e-09 1.70998202e-09 1.73491710e-09\n  1.60404161e-09 1.67156231e-09 1.76111015e-09 1.80508995e-09\n  1.68522315e-09 1.80848440e-09 1.63892009e-09 1.43076361e-09\n  1.59081122e-09 1.62859451e-09 1.45816380e-09 1.67424227e-09\n  1.69869008e-09 1.63898362e-09 1.68436100e-09 1.74909595e-09\n  1.78661295e-09 1.66251204e-09 1.87733725e-09 1.65753387e-09\n  1.57112132e-09 1.64304137e-09 1.73456984e-09 1.45154370e-09\n  1.65970106e-09 1.82565374e-09 1.90129790e-09 1.44749317e-09\n  1.56819344e-09 1.47497281e-09 1.38590534e-09 1.60361251e-09\n  1.73628662e-09 1.51396943e-09 1.57376203e-09 1.55065150e-09\n  1.78989550e-09 1.66418041e-09 1.61756090e-09 1.49505375e-09\n  1.69619138e-09 1.68526226e-09 1.46675931e-09 1.48306332e-09]\n [1.66656512e-09 1.63584646e-09 1.60934420e-09 1.68163934e-09\n  1.70259090e-09 1.68982613e-09 1.73278060e-09 1.37198231e-09\n  1.54060410e-09 1.78508925e-09 1.83097055e-09 1.65782361e-09\n  1.51893566e-09 1.60628829e-09 1.57650016e-09 1.59649662e-09\n  1.59814790e-09 1.48550398e-09 1.65866592e-09 1.78358568e-09\n  1.53536456e-09 1.53465051e-09 1.69082418e-09 1.41794629e-09\n  1.50416311e-09 1.59716145e-09 1.63137757e-09 1.42529018e-09\n  1.57221962e-09 1.51625868e-09 1.40007382e-09 1.54300129e-09\n  1.47251244e-09 1.58004646e-09 1.58476995e-09 1.73128146e-09\n  1.77149230e-09 1.54112072e-09 1.43507216e-09 1.43828093e-09\n  1.51772656e-09 1.51706556e-09 1.55027040e-09 1.49411006e-09\n  1.73640977e-09 1.58390809e-09 1.54245494e-09 1.45213793e-09\n  1.49314355e-09 1.55798360e-09 1.58390975e-09 1.79854385e-09\n  1.53965828e-09 1.64011849e-09 1.63250799e-09 1.67182273e-09\n  1.59765870e-09 1.65941914e-09 1.73336046e-09 1.76630606e-09\n  1.66133735e-09 1.77634630e-09 1.59874828e-09 1.40871228e-09\n  1.58405693e-09 1.60877084e-09 1.43872164e-09 1.63851913e-09\n  1.65712803e-09 1.61972711e-09 1.67697982e-09 1.68114312e-09\n  1.74498642e-09 1.58671728e-09 1.80262576e-09 1.58754296e-09\n  1.52522087e-09 1.57465527e-09 1.70623344e-09 1.45611515e-09\n  1.63953173e-09 1.76547720e-09 1.84743137e-09 1.42063863e-09\n  1.57311545e-09 1.48358170e-09 1.38917522e-09 1.60593256e-09\n  1.66315416e-09 1.52927036e-09 1.52736517e-09 1.54617200e-09\n  1.76022341e-09 1.62782354e-09 1.61071767e-09 1.48849101e-09\n  1.61906053e-09 1.66272080e-09 1.45277023e-09 1.45098334e-09]\n [1.65321677e-09 1.60934420e-09 1.60406892e-09 1.68772457e-09\n  1.63367768e-09 1.64435414e-09 1.72837603e-09 1.37032247e-09\n  1.57935236e-09 1.75694281e-09 1.77830824e-09 1.65587378e-09\n  1.53944494e-09 1.64124103e-09 1.55160037e-09 1.61175644e-09\n  1.58621525e-09 1.51281314e-09 1.63462002e-09 1.72929108e-09\n  1.52580037e-09 1.47936794e-09 1.66406748e-09 1.40719583e-09\n  1.49501880e-09 1.56891010e-09 1.54955600e-09 1.41603066e-09\n  1.52849098e-09 1.48897552e-09 1.39260784e-09 1.49444552e-09\n  1.47343791e-09 1.51451711e-09 1.51757443e-09 1.66444800e-09\n  1.71032485e-09 1.48121814e-09 1.41811528e-09 1.42017390e-09\n  1.51066573e-09 1.54468572e-09 1.51494819e-09 1.45576872e-09\n  1.73143925e-09 1.58897947e-09 1.56583901e-09 1.43727595e-09\n  1.44641467e-09 1.48841926e-09 1.53855576e-09 1.77950088e-09\n  1.54615580e-09 1.61588179e-09 1.66111413e-09 1.67461790e-09\n  1.55137975e-09 1.60615333e-09 1.68114669e-09 1.71899222e-09\n  1.62118918e-09 1.71906937e-09 1.59152895e-09 1.42051142e-09\n  1.54116416e-09 1.57565910e-09 1.44132845e-09 1.61721598e-09\n  1.63836925e-09 1.58353412e-09 1.61428504e-09 1.68739511e-09\n  1.70595421e-09 1.62383832e-09 1.78764848e-09 1.61767645e-09\n  1.54087028e-09 1.60581150e-09 1.66096996e-09 1.42677854e-09\n  1.59998820e-09 1.74284006e-09 1.79777482e-09 1.43574188e-09\n  1.51900360e-09 1.44390343e-09 1.37469482e-09 1.54776167e-09\n  1.67960521e-09 1.47232535e-09 1.54313355e-09 1.50876186e-09\n  1.70393132e-09 1.60966329e-09 1.56211965e-09 1.46563877e-09\n  1.65036287e-09 1.62070828e-09 1.44604253e-09 1.46605788e-09]\n [1.74954823e-09 1.68163934e-09 1.68772457e-09 1.80929678e-09\n  1.68889828e-09 1.71753354e-09 1.85868101e-09 1.37983465e-09\n  1.68251233e-09 1.88314903e-09 1.89746284e-09 1.76040955e-09\n  1.61687163e-09 1.76430821e-09 1.60479977e-09 1.71123894e-09\n  1.65938983e-09 1.58553705e-09 1.71748444e-09 1.82852957e-09\n  1.57969336e-09 1.49060973e-09 1.75597772e-09 1.42231760e-09\n  1.53894428e-09 1.62599173e-09 1.56825354e-09 1.43475972e-09\n  1.56253787e-09 1.51989706e-09 1.40528191e-09 1.51446775e-09\n  1.51653136e-09 1.53111450e-09 1.53420039e-09 1.73196690e-09\n  1.79819676e-09 1.49035992e-09 1.43285129e-09 1.43485363e-09\n  1.56104523e-09 1.62847993e-09 1.54953939e-09 1.46948666e-09\n  1.86256129e-09 1.67382372e-09 1.65425303e-09 1.45921152e-09\n  1.45228164e-09 1.49426663e-09 1.57499070e-09 1.92036148e-09\n  1.61698796e-09 1.69190317e-09 1.78737945e-09 1.78914963e-09\n  1.59157581e-09 1.66101982e-09 1.76363482e-09 1.81863277e-09\n  1.68931548e-09 1.81260646e-09 1.66951988e-09 1.45351618e-09\n  1.57994570e-09 1.63210377e-09 1.47518586e-09 1.69553366e-09\n  1.72588768e-09 1.64083125e-09 1.66635925e-09 1.80895083e-09\n  1.80580852e-09 1.74194424e-09 1.93435403e-09 1.72895002e-09\n  1.61568664e-09 1.71346184e-09 1.74030702e-09 1.43680092e-09\n  1.66099029e-09 1.86706826e-09 1.92647176e-09 1.47557875e-09\n  1.54375594e-09 1.45312196e-09 1.37781286e-09 1.57967025e-09\n  1.80484473e-09 1.48036445e-09 1.61880208e-09 1.54006535e-09\n  1.79238717e-09 1.68724280e-09 1.60457082e-09 1.49171775e-09\n  1.77440098e-09 1.68752614e-09 1.47566862e-09 1.51557342e-09]\n [1.70960115e-09 1.70259090e-09 1.63367768e-09 1.68889828e-09\n  1.85964627e-09 1.79761585e-09 1.76276010e-09 1.37689064e-09\n  1.48132832e-09 1.86413213e-09 1.96213466e-09 1.67869599e-09\n  1.49077859e-09 1.55709731e-09 1.63668633e-09 1.58201896e-09\n  1.63449134e-09 1.44350146e-09 1.72194382e-09 1.91511010e-09\n  1.56367166e-09 1.65369141e-09 1.76133147e-09 1.44227207e-09\n  1.52997128e-09 1.66510294e-09 1.81200472e-09 1.44716180e-09\n  1.66965388e-09 1.57776375e-09 1.41727022e-09 1.64864176e-09\n  1.47771122e-09 1.72299713e-09 1.73150070e-09 1.88565759e-09\n  1.91646894e-09 1.67013234e-09 1.47215531e-09 1.47774806e-09\n  1.54032202e-09 1.47612284e-09 1.62957399e-09 1.57638435e-09\n  1.76768166e-09 1.58744331e-09 1.51038281e-09 1.48608548e-09\n  1.59235278e-09 1.70829024e-09 1.68529993e-09 1.86065031e-09\n  1.53811894e-09 1.70267627e-09 1.59598801e-09 1.68462776e-09\n  1.70170849e-09 1.78132692e-09 1.85752220e-09 1.88249592e-09\n  1.75668447e-09 1.91356308e-09 1.62615527e-09 1.39067209e-09\n  1.68046613e-09 1.68698990e-09 1.43904908e-09 1.69526437e-09\n  1.71003163e-09 1.70471517e-09 1.81946928e-09 1.68806339e-09\n  1.84314719e-09 1.53267679e-09 1.85713048e-09 1.54585578e-09\n  1.50616579e-09 1.53046903e-09 1.81458631e-09 1.51843655e-09\n  1.73238207e-09 1.83249795e-09 1.97351379e-09 1.39720590e-09\n  1.69184358e-09 1.56798176e-09 1.41915931e-09 1.73491068e-09\n  1.65027186e-09 1.65147376e-09 1.50820829e-09 1.62942191e-09\n  1.89441318e-09 1.67785043e-09 1.72023978e-09 1.53981790e-09\n  1.57700894e-09 1.76190301e-09 1.47127543e-09 1.42912064e-09]\n [1.71470853e-09 1.68982613e-09 1.64435414e-09 1.71753354e-09\n  1.79761585e-09 1.76506995e-09 1.78298534e-09 1.37708592e-09\n  1.53609747e-09 1.85996650e-09 1.93088241e-09 1.69650151e-09\n  1.52462736e-09 1.61224091e-09 1.62189637e-09 1.61513787e-09\n  1.63663736e-09 1.48260716e-09 1.71372199e-09 1.87817775e-09\n  1.56451879e-09 1.59790338e-09 1.75206232e-09 1.43453847e-09\n  1.52934286e-09 1.64759780e-09 1.72730896e-09 1.44161127e-09\n  1.63122089e-09 1.55618248e-09 1.41234528e-09 1.60211663e-09\n  1.48678420e-09 1.65674801e-09 1.66335267e-09 1.82850340e-09\n  1.86974820e-09 1.60870817e-09 1.45807305e-09 1.46248065e-09\n  1.54297835e-09 1.51755728e-09 1.60025791e-09 1.53969417e-09\n  1.78751063e-09 1.60830568e-09 1.54887225e-09 1.47552154e-09\n  1.54494877e-09 1.63511687e-09 1.64558377e-09 1.86844572e-09\n  1.55772281e-09 1.69295141e-09 1.64612897e-09 1.70884000e-09\n  1.66174155e-09 1.73667596e-09 1.81953481e-09 1.85316896e-09\n  1.72883361e-09 1.87225012e-09 1.63386525e-09 1.40819286e-09\n  1.64388134e-09 1.66428932e-09 1.44800117e-09 1.68896907e-09\n  1.70805995e-09 1.67893628e-09 1.76379653e-09 1.71685299e-09\n  1.82265052e-09 1.58879416e-09 1.87006094e-09 1.59459480e-09\n  1.53507386e-09 1.57944437e-09 1.78347554e-09 1.49059931e-09\n  1.70377724e-09 1.83355571e-09 1.94734521e-09 1.41908646e-09\n  1.64014595e-09 1.52894619e-09 1.40534512e-09 1.68016042e-09\n  1.68923805e-09 1.59315468e-09 1.53738446e-09 1.59723358e-09\n  1.85316649e-09 1.67459573e-09 1.67820088e-09 1.52188882e-09\n  1.62912811e-09 1.73180942e-09 1.47032026e-09 1.45278463e-09]\n [1.80204387e-09 1.73278060e-09 1.72837603e-09 1.85868101e-09\n  1.76276010e-09 1.78298534e-09 1.92014723e-09 1.38504619e-09\n  1.69858278e-09 1.96081455e-09 1.99025758e-09 1.80809900e-09\n  1.63547921e-09 1.79210786e-09 1.64598640e-09 1.74360079e-09\n  1.70020832e-09 1.59700099e-09 1.77171304e-09 1.91291752e-09\n  1.61005533e-09 1.53403853e-09 1.81643168e-09 1.43634908e-09\n  1.56454362e-09 1.67138966e-09 1.63366243e-09 1.44931598e-09\n  1.60842060e-09 1.55266077e-09 1.41593633e-09 1.55726871e-09\n  1.53447808e-09 1.58417941e-09 1.58843946e-09 1.81025351e-09\n  1.88217400e-09 1.53601732e-09 1.45108022e-09 1.45386607e-09\n  1.58801331e-09 1.64453700e-09 1.58969506e-09 1.50224731e-09\n  1.92484247e-09 1.70728617e-09 1.67553812e-09 1.47914093e-09\n  1.48729866e-09 1.54505808e-09 1.62313604e-09 1.99802743e-09\n  1.64311826e-09 1.74310208e-09 1.82153394e-09 1.83781941e-09\n  1.64212958e-09 1.72346758e-09 1.83844910e-09 1.89803157e-09\n  1.74850128e-09 1.89645252e-09 1.70904174e-09 1.45922670e-09\n  1.62742717e-09 1.68073312e-09 1.48788059e-09 1.74562962e-09\n  1.77834921e-09 1.69208824e-09 1.73425406e-09 1.85819967e-09\n  1.87914650e-09 1.76585732e-09 2.01165837e-09 1.75522049e-09\n  1.63677660e-09 1.73733798e-09 1.80852030e-09 1.46160653e-09\n  1.71640227e-09 1.93961058e-09 2.02162833e-09 1.48183310e-09\n  1.59265569e-09 1.48477153e-09 1.38922147e-09 1.63478564e-09\n  1.84793468e-09 1.52345938e-09 1.64017939e-09 1.58019806e-09\n  1.87306016e-09 1.73467673e-09 1.65783232e-09 1.51915334e-09\n  1.80546568e-09 1.74745676e-09 1.49320270e-09 1.52602365e-09]\n [1.37665086e-09 1.37198231e-09 1.37032247e-09 1.37983465e-09\n  1.37689064e-09 1.37708592e-09 1.38504619e-09 1.33948989e-09\n  1.36509258e-09 1.38936301e-09 1.39282639e-09 1.37643381e-09\n  1.36095967e-09 1.37291353e-09 1.36476291e-09 1.37027187e-09\n  1.36844562e-09 1.35718082e-09 1.37492450e-09 1.38737727e-09\n  1.36073231e-09 1.35703651e-09 1.37856300e-09 1.34509950e-09\n  1.35674012e-09 1.36709018e-09 1.36725124e-09 1.34622693e-09\n  1.36276950e-09 1.35687616e-09 1.34291403e-09 1.35865355e-09\n  1.35339200e-09 1.36206185e-09 1.36253142e-09 1.38043657e-09\n  1.38551086e-09 1.35750754e-09 1.34692082e-09 1.34726140e-09\n  1.35866188e-09 1.36126793e-09 1.36062985e-09 1.35308429e-09\n  1.38542400e-09 1.36796020e-09 1.36416332e-09 1.34939972e-09\n  1.35227480e-09 1.35891814e-09 1.36412102e-09 1.39149988e-09\n  1.36252021e-09 1.37266975e-09 1.37561438e-09 1.37844061e-09\n  1.36577610e-09 1.37285618e-09 1.38173194e-09 1.38589140e-09\n  1.37406135e-09 1.38634147e-09 1.36887363e-09 1.34570635e-09\n  1.36432959e-09 1.36816238e-09 1.34902205e-09 1.37269269e-09\n  1.37512686e-09 1.36928285e-09 1.37427905e-09 1.37978813e-09\n  1.38402058e-09 1.37068732e-09 1.39223260e-09 1.37027357e-09\n  1.36138756e-09 1.36876313e-09 1.37904704e-09 1.34874665e-09\n  1.37145997e-09 1.38751970e-09 1.39485496e-09 1.34760053e-09\n  1.36207410e-09 1.35157851e-09 1.34080651e-09 1.36589744e-09\n  1.37839232e-09 1.35620267e-09 1.36166998e-09 1.35994095e-09\n  1.38455855e-09 1.37162431e-09 1.36722730e-09 1.35359269e-09\n  1.37419268e-09 1.37409055e-09 1.35014832e-09 1.35167269e-09]\n [1.60898489e-09 1.54060410e-09 1.57935236e-09 1.68251233e-09\n  1.48132832e-09 1.53609747e-09 1.69858278e-09 1.36509258e-09\n  1.65281909e-09 1.67668934e-09 1.64849721e-09 1.63533816e-09\n  1.57392774e-09 1.70241067e-09 1.48914963e-09 1.63068950e-09\n  1.54853887e-09 1.56396844e-09 1.56948661e-09 1.59918278e-09\n  1.49621842e-09 1.36099844e-09 1.59184008e-09 1.38103451e-09\n  1.46788652e-09 1.49879128e-09 1.37820190e-09 1.39256219e-09\n  1.42982942e-09 1.42491347e-09 1.37402547e-09 1.38818129e-09\n  1.46868964e-09 1.37501520e-09 1.37480630e-09 1.51424409e-09\n  1.56818305e-09 1.35401206e-09 1.37856269e-09 1.37815709e-09\n  1.48710392e-09 1.59478851e-09 1.43350753e-09 1.37134844e-09\n  1.70028226e-09 1.58706815e-09 1.60527262e-09 1.40111886e-09\n  1.34610550e-09 1.34281452e-09 1.43620632e-09 1.71642003e-09\n  1.54960859e-09 1.55137395e-09 1.70679825e-09 1.66311083e-09\n  1.44656106e-09 1.48492055e-09 1.55778197e-09 1.60297033e-09\n  1.52461997e-09 1.58383335e-09 1.56340341e-09 1.44196571e-09\n  1.44347379e-09 1.49545502e-09 1.44179198e-09 1.55860066e-09\n  1.58380910e-09 1.49679203e-09 1.47467792e-09 1.68255926e-09\n  1.60689783e-09 1.69097242e-09 1.73243951e-09 1.66931478e-09\n  1.56453669e-09 1.66044127e-09 1.55220197e-09 1.36165914e-09\n  1.50575214e-09 1.67453972e-09 1.67263700e-09 1.46370243e-09\n  1.40080815e-09 1.35744412e-09 1.34231555e-09 1.42032499e-09\n  1.69730738e-09 1.35116352e-09 1.56693973e-09 1.42350828e-09\n  1.57144556e-09 1.55788129e-09 1.45224200e-09 1.41170657e-09\n  1.70273608e-09 1.52050443e-09 1.42642651e-09 1.49240286e-09]\n [1.84456260e-09 1.78508925e-09 1.75694281e-09 1.88314903e-09\n  1.86413213e-09 1.85996650e-09 1.96081455e-09 1.38936301e-09\n  1.67668934e-09 2.03174967e-09 2.09178296e-09 1.83824657e-09\n  1.63007755e-09 1.77976693e-09 1.69057311e-09 1.75036817e-09\n  1.73425859e-09 1.58209517e-09 1.82404585e-09 2.00999855e-09\n  1.63572289e-09 1.60337632e-09 1.87499904e-09 1.45286273e-09\n  1.58694345e-09 1.72134823e-09 1.73875479e-09 1.46502143e-09\n  1.67073061e-09 1.59363375e-09 1.42790246e-09 1.62113325e-09\n  1.54436500e-09 1.66802729e-09 1.67438124e-09 1.91314733e-09\n  1.98455231e-09 1.61036594e-09 1.47489393e-09 1.47904104e-09\n  1.60961948e-09 1.63189018e-09 1.64170126e-09 1.55159421e-09\n  1.96649193e-09 1.72308140e-09 1.66927984e-09 1.50243408e-09\n  1.54442484e-09 1.63025631e-09 1.68823559e-09 2.06128651e-09\n  1.65341514e-09 1.79363186e-09 1.81811565e-09 1.86461548e-09\n  1.70958735e-09 1.80454827e-09 1.92724060e-09 1.98598798e-09\n  1.81700723e-09 1.99558737e-09 1.73848924e-09 1.45350456e-09\n  1.69018121e-09 1.73663998e-09 1.49334842e-09 1.79308997e-09\n  1.82526298e-09 1.75216235e-09 1.82651932e-09 1.88244623e-09\n  1.95623793e-09 1.74955521e-09 2.07122800e-09 1.74611411e-09\n  1.63673931e-09 1.72604993e-09 1.88721058e-09 1.49893551e-09\n  1.78189502e-09 2.00260478e-09 2.12226392e-09 1.47382915e-09\n  1.66495471e-09 1.53436657e-09 1.40690943e-09 1.71453337e-09\n  1.85993697e-09 1.59379557e-09 1.64020961e-09 1.63378912e-09\n  1.96919293e-09 1.77790594e-09 1.72893789e-09 1.55329357e-09\n  1.79803012e-09 1.81794500e-09 1.50878897e-09 1.52040366e-09]]\n"
     ]
    }
   ],
   "source": [
    "K = rbf_kernel(data, data, 1.8)\n",
    "print(f\"K: {K.shape}\")\n",
    "print(K[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halving(K, m, candidate_index=None, lambda_=0.001):\n",
    "    \n",
    "    n = K.shape[0]\n",
    "    print(f'number of data: {n}')\n",
    "\n",
    "    m = min(n, m)\n",
    "    print(f'number of samples: {m}')\n",
    "\n",
    "    if candidate_index is None:\n",
    "        candidate_index = np.array(range(n))\n",
    "    \n",
    "    # print(f'candidate_index: {candidate_index}')\n",
    "\n",
    "    q = len(candidate_index)\n",
    "\n",
    "    index = np.empty(m, dtype=int)\n",
    "    # print(f'number of index: {index.shape}')\n",
    "\n",
    "    print('Selecting samples......')\n",
    "    for i in range(m):\n",
    "        score = np.zeros(q)\n",
    "        for j in range(q):\n",
    "            k = candidate_index[j]\n",
    "            # print(k)\n",
    "            score[j] = np.dot(K[k, :], K[:, k]) / (K[k, k] + lambda_)\n",
    "        \n",
    "        I = score.argmax()\n",
    "        # print(I)\n",
    "        index[i] = candidate_index[I]\n",
    "\n",
    "        # update K\n",
    "        # K = K - np.dot(K[:, index[i]], K[index[i], :]) / (K[index[i], index[i]] + lambda_)\n",
    "        K = K - K[:, index[i]][:, np.newaxis] @ K[index[i], :][np.newaxis, :] / (K[index[i], index[i]] + lambda_)\n",
    "\n",
    "    print('Done.\\n')\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of data: 100\nnumber of samples: 50\nSelecting samples......\nDone.\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
       "       82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
       "       82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# K_random = np.random.rand(10, 10)\n",
    "id = halving(K, num_samples)\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_density(data, center, radius):\n",
    "    print(f'length of data: {len(data)}\\nlength of center: {len(center)}')\n",
    "    f = 0\n",
    "    for i in range(len(data)):\n",
    "        ball_dist = np.zeros(len(center))\n",
    "        dist = np.ones(len(center))\n",
    "        for j in range(len(center)):\n",
    "            dist[j] = np.linalg.norm(data[i, :] - center[j, :])\n",
    "            if dist[j] < radius:\n",
    "                ball_dist[j] = dist[j]\n",
    "\n",
    "        # print(np.exp(ball_dist/1.8))\n",
    "        f += np.sum(np.exp(ball_dist/1.8)**2) / (len(ball_dist) + 1)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=num_centers).fit(data)\n",
    "center = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length of data: 80\nlength of center: 4\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "66.87375596462208"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "f = number_density(data, center, radius=0.25)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDAL(data, k):\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k).fit(data)\n",
    "    center = kmeans.cluster_centers_\n",
    "\n",
    "    radius = 0.25\n",
    "    L, R = data.shape\n",
    "    \n",
    "    f = number_density(data, center, radius)\n",
    "    T = 0\n",
    "    while T<50:\n",
    "        for j in range(k):\n",
    "            ball = []\n",
    "            dist = np.empty(L)\n",
    "            for i in range(L):\n",
    "                dist[i] = np.linalg.norm(data[i] - center[j])\n",
    "                if dist[i] < radius:\n",
    "                    ball.append(data[i])\n",
    "            if len(ball)==0:\n",
    "                center[j] = center[j]\n",
    "            else:\n",
    "                center[j] = np.mean(ball)\n",
    "\n",
    "        F = number_density(data, center, radius)\n",
    "        \n",
    "        if F-f==0 or len(np.argwhere(pdist(center)<2*radius))>0:\n",
    "            break\n",
    "        else:\n",
    "            f = F\n",
    "        T+=1\n",
    "        radius*=1.1\n",
    "    \n",
    "    tree = KDTree(data)\n",
    "    _, idx = tree.query(center, k=1)\n",
    "    # print(idx)\n",
    "    center = data[idx].squeeze()\n",
    "            \n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length of data: 80\nlength of center: 4\nlength of data: 80\nlength of center: 4\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "center = SDAL(data, num_centers)\n",
    "center.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('Syndata.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "type(mat['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}